{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora():\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "Training GCN...\n",
      "Epoch 0, Loss: 1.9464\n",
      "Epoch 20, Loss: 0.2512\n",
      "Epoch 40, Loss: 0.0693\n",
      "Epoch 60, Loss: 0.0755\n",
      "Epoch 80, Loss: 0.0426\n",
      "Epoch 100, Loss: 0.0490\n",
      "Epoch 120, Loss: 0.0478\n",
      "Epoch 140, Loss: 0.0366\n",
      "Epoch 160, Loss: 0.0287\n",
      "Epoch 180, Loss: 0.0315\n",
      "GCN Test Accuracy: 0.8160\n",
      "\n",
      "Training SGC...\n",
      "Epoch 0, Loss: 1.9506\n",
      "Epoch 20, Loss: 0.4455\n",
      "Epoch 40, Loss: 0.1728\n",
      "Epoch 60, Loss: 0.1200\n",
      "Epoch 80, Loss: 0.1057\n",
      "Epoch 100, Loss: 0.0977\n",
      "Epoch 120, Loss: 0.0912\n",
      "Epoch 140, Loss: 0.0859\n",
      "Epoch 160, Loss: 0.0817\n",
      "Epoch 180, Loss: 0.0784\n",
      "SGC Test Accuracy: 0.8000\n",
      "\n",
      "Comparison:\n",
      "GCN Test Accuracy: 0.8160\n",
      "SGC Test Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "# Load the Cora dataset\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "print(f'Dataset: {dataset}:')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Number of features: {dataset.num_node_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Compute the normalized adjacency matrix for SGC\n",
    "# Add self-loops to the adjacency matrix\n",
    "edge_index, _ = add_self_loops(data.edge_index, num_nodes=data.num_nodes)\n",
    "row, col = edge_index\n",
    "# Compute degree and normalization factors\n",
    "deg = degree(row, data.num_nodes, dtype=data.x.dtype)\n",
    "deg_inv_sqrt = deg.pow(-0.5)\n",
    "deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "# Create sparse adjacency matrix\n",
    "adj = torch.sparse_coo_tensor(edge_index, norm, torch.Size([data.num_nodes, data.num_nodes]))\n",
    "\n",
    "# Precompute feature matrix for SGC (A^K * X)\n",
    "K = 2  # Number of hops, matching two-layer GCN\n",
    "x = data.x\n",
    "for _ in range(K):\n",
    "    x = torch.spmm(adj, x)  # Sparse matrix multiplication\n",
    "feature_matrix = x\n",
    "\n",
    "# Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Define the SGC model (linear version)\n",
    "class SGC(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SGC, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Instantiate the models\n",
    "gcn_model = GCN()\n",
    "sgc_model = SGC(dataset.num_node_features, dataset.num_classes)\n",
    "\n",
    "# Set up optimizers\n",
    "optimizer_gcn = torch.optim.Adam(gcn_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "optimizer_sgc = torch.optim.Adam(sgc_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Training and evaluation functions for GCN\n",
    "def train_gcn():\n",
    "    gcn_model.train()\n",
    "    optimizer_gcn.zero_grad()\n",
    "    out = gcn_model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer_gcn.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test_gcn():\n",
    "    gcn_model.eval()\n",
    "    out = gcn_model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    return acc\n",
    "\n",
    "# Training and evaluation functions for SGC\n",
    "def train_sgc():\n",
    "    sgc_model.train()\n",
    "    optimizer_sgc.zero_grad()\n",
    "    out = sgc_model(feature_matrix)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer_sgc.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test_sgc():\n",
    "    sgc_model.eval()\n",
    "    out = sgc_model(feature_matrix)\n",
    "    pred = out.argmax(dim=1)\n",
    "    acc = (pred[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()\n",
    "    return acc\n",
    "\n",
    "# Train GCN\n",
    "print(\"\\nTraining GCN...\")\n",
    "for epoch in range(200):\n",
    "    loss = train_gcn()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "gcn_acc = test_gcn()\n",
    "print(f'GCN Test Accuracy: {gcn_acc:.4f}')\n",
    "\n",
    "# Train SGC\n",
    "print(\"\\nTraining SGC...\")\n",
    "for epoch in range(200):\n",
    "    loss = train_sgc()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "sgc_acc = test_sgc()\n",
    "print(f'SGC Test Accuracy: {sgc_acc:.4f}')\n",
    "\n",
    "# Compare results\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"GCN Test Accuracy: {gcn_acc:.4f}\")\n",
    "print(f\"SGC Test Accuracy: {sgc_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: Data(x=[5201, 2089], edge_index=[2, 217073], y=[5201], train_mask=[5201, 10], val_mask=[5201, 10], test_mask=[5201, 10])\n",
      "Graph file 'ind.squirrel.graph' not found. Using data.edge_index.\n",
      "Directed edge_index shape: torch.Size([2, 217073])\n",
      "\n",
      "Training DirGCN...\n",
      "Epoch 0, Loss: 1.6097\n",
      "Epoch 20, Loss: 1.3986\n",
      "Epoch 40, Loss: 1.2550\n",
      "Epoch 60, Loss: 1.1661\n",
      "Epoch 80, Loss: 1.1202\n",
      "Epoch 100, Loss: 1.0719\n",
      "Epoch 120, Loss: 1.0344\n",
      "Epoch 140, Loss: 1.0119\n",
      "Epoch 160, Loss: 0.9785\n",
      "Epoch 180, Loss: 0.9896\n",
      "DirGCN Test Accuracy: 0.4745\n",
      "\n",
      "Training GCN...\n",
      "Epoch 0, Loss: 1.6253\n",
      "Epoch 20, Loss: 1.3987\n",
      "Epoch 40, Loss: 1.2130\n",
      "Epoch 60, Loss: 1.0959\n",
      "Epoch 80, Loss: 1.0244\n",
      "Epoch 100, Loss: 0.9603\n",
      "Epoch 120, Loss: 0.9149\n",
      "Epoch 140, Loss: 0.8841\n",
      "Epoch 160, Loss: 0.8691\n",
      "Epoch 180, Loss: 0.8431\n",
      "GCN Test Accuracy: 0.2248\n",
      "\n",
      "Training LinearDirGCN...\n",
      "Epoch 0, Loss: 1.6094\n",
      "Epoch 20, Loss: 1.2872\n",
      "Epoch 40, Loss: 1.1680\n",
      "Epoch 60, Loss: 1.1289\n",
      "Epoch 80, Loss: 1.1136\n",
      "Epoch 100, Loss: 1.1056\n",
      "Epoch 120, Loss: 1.1011\n",
      "Epoch 140, Loss: 1.0985\n",
      "Epoch 160, Loss: 1.0970\n",
      "Epoch 180, Loss: 1.0960\n",
      "LinearDirGCN Test Accuracy: 0.4294\n",
      "\n",
      "Training LinearGCN...\n",
      "Epoch 0, Loss: 1.6099\n",
      "Epoch 20, Loss: 1.4027\n",
      "Epoch 40, Loss: 1.2978\n",
      "Epoch 60, Loss: 1.2488\n",
      "Epoch 80, Loss: 1.2255\n",
      "Epoch 100, Loss: 1.2134\n",
      "Epoch 120, Loss: 1.2065\n",
      "Epoch 140, Loss: 1.2025\n",
      "Epoch 160, Loss: 1.2001\n",
      "Epoch 180, Loss: 1.1986\n",
      "LinearGCN Test Accuracy: 0.3958\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import WikipediaNetwork\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import degree, to_undirected, add_self_loops\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# -------------------------------\n",
    "# Load Squirrel Dataset\n",
    "# -------------------------------\n",
    "root_dir = './data/Wikipedia'\n",
    "dataset = WikipediaNetwork(root=root_dir, name='squirrel')\n",
    "data = dataset[0]\n",
    "print(f\"Graph: {data}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Build Directed Edge List\n",
    "# -------------------------------\n",
    "raw_dir = Path(dataset.raw_dir)\n",
    "graph_file = f'ind.{dataset.name.lower()}.graph'\n",
    "graph_path = raw_dir / graph_file\n",
    "\n",
    "if graph_path.exists():\n",
    "    print(f\"Loading graph from '{graph_file}'...\")\n",
    "    with open(graph_path, 'rb') as f:\n",
    "        graph = pickle.load(f)\n",
    "    directed_edges = [(src, nbr) for src, neighbors in graph.items() for nbr in neighbors]\n",
    "    directed_edge_index = torch.tensor(directed_edges, dtype=torch.long).t().contiguous() if directed_edges else data.edge_index\n",
    "    if not directed_edges:\n",
    "        print(\"Warning: No edges found. Using processed edge_index as fallback.\")\n",
    "else:\n",
    "    print(f\"Graph file '{graph_file}' not found. Using data.edge_index.\")\n",
    "    directed_edge_index = data.edge_index\n",
    "\n",
    "print(f\"Directed edge_index shape: {directed_edge_index.shape}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Build Propagation Matrices\n",
    "# -------------------------------\n",
    "num_nodes = data.num_nodes\n",
    "\n",
    "# **Directed Propagation Matrices** (for DirGCN and LinearDirGCN)\n",
    "out_deg = degree(directed_edge_index[0], num_nodes, dtype=torch.float)\n",
    "in_deg = degree(directed_edge_index[1], num_nodes, dtype=torch.float)\n",
    "out_deg_inv_sqrt = out_deg.pow(-0.5)\n",
    "in_deg_inv_sqrt = in_deg.pow(-0.5)\n",
    "out_deg_inv_sqrt[out_deg_inv_sqrt == float('inf')] = 0\n",
    "in_deg_inv_sqrt[in_deg_inv_sqrt == float('inf')] = 0\n",
    "edge_weights = out_deg_inv_sqrt[directed_edge_index[0]] * in_deg_inv_sqrt[directed_edge_index[1]]\n",
    "S_forward = torch.sparse_coo_tensor(directed_edge_index, edge_weights, (num_nodes, num_nodes)).coalesce()\n",
    "S_backward = torch.sparse_coo_tensor(directed_edge_index[[1, 0]], edge_weights, (num_nodes, num_nodes)).coalesce()\n",
    "\n",
    "# **Undirected Propagation Matrix** (for GCN and LinearGCN)\n",
    "undirected_edge_index = to_undirected(directed_edge_index)\n",
    "undirected_edge_index, _ = add_self_loops(undirected_edge_index, num_nodes=num_nodes)\n",
    "deg = degree(undirected_edge_index[0], num_nodes, dtype=torch.float)\n",
    "deg_inv_sqrt = deg.pow(-0.5)\n",
    "deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "edge_weights_undirected = deg_inv_sqrt[undirected_edge_index[0]] * deg_inv_sqrt[undirected_edge_index[1]]\n",
    "S_undirected = torch.sparse_coo_tensor(undirected_edge_index, edge_weights_undirected, (num_nodes, num_nodes)).coalesce()\n",
    "\n",
    "# -------------------------------\n",
    "# Model Definitions\n",
    "# -------------------------------\n",
    "\n",
    "class DirGCNLayer(torch.nn.Module):\n",
    "    \"\"\"Nonlinear layer for directed GCN with separate weights for in/out edges.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.W_forward = torch.nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.W_backward = torch.nn.Linear(in_channels, out_channels, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_forward = torch.spmm(S_forward, x)\n",
    "        x_backward = torch.spmm(S_backward, x)\n",
    "        return self.W_forward(x_forward) + self.W_backward(x_backward)\n",
    "\n",
    "class DirGCN(torch.nn.Module):\n",
    "    \"\"\"Two-layer directed GCN.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = DirGCNLayer(dataset.num_node_features, 16)\n",
    "        self.layer2 = DirGCNLayer(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.layer1(data.x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.layer2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"Two-layer GCN, agnostic to edge direction.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = F.relu(self.conv1(data.x, data.edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, data.edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class LinearDirGCN(torch.nn.Module):\n",
    "    \"\"\"Linear version of DirGCN with separate weights for in/out edges.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, K=1):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.lin_forward = torch.nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.lin_backward = torch.nn.Linear(in_channels, out_channels, bias=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x_forward = x_backward = x\n",
    "        for _ in range(self.K):\n",
    "            x_forward = torch.spmm(S_forward, x_forward)\n",
    "            x_backward = torch.spmm(S_backward, x_backward)\n",
    "        out = self.lin_forward(x_forward) + self.lin_backward(x_backward)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "class LinearGCN(torch.nn.Module):\n",
    "    \"\"\"Linear version of GCN, agnostic to edge direction.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, K=1):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.linear = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        for _ in range(self.K):\n",
    "            x = torch.spmm(S_undirected, x)\n",
    "        return F.log_softmax(self.linear(x), dim=1)\n",
    "\n",
    "# -------------------------------\n",
    "# Instantiate Models & Optimizers\n",
    "# -------------------------------\n",
    "models = {\n",
    "    'DirGCN': DirGCN(),\n",
    "    'GCN': GCN(),\n",
    "    'LinearDirGCN': LinearDirGCN(dataset.num_node_features, dataset.num_classes),\n",
    "    'LinearGCN': LinearGCN(dataset.num_node_features, dataset.num_classes)\n",
    "}\n",
    "\n",
    "optimizers = {name: torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4) \n",
    "              for name, model in models.items()}\n",
    "\n",
    "# -------------------------------\n",
    "# Training and Evaluation Functions\n",
    "# -------------------------------\n",
    "def train(model, optimizer, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask[:, 0]], data.y[data.train_mask[:, 0]])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    acc = (pred[data.test_mask[:, 0]] == data.y[data.test_mask[:, 0]]).sum().item() / data.test_mask[:, 0].sum().item()\n",
    "    return acc\n",
    "\n",
    "# -------------------------------\n",
    "# Training Loops and Comparison\n",
    "# -------------------------------\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    optimizer = optimizers[name]\n",
    "    for epoch in range(200):\n",
    "        loss = train(model, optimizer, data)\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "    acc = test(model, data)\n",
    "    print(f\"{name} Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original directed adjacency matrix (COO format):\n",
      "Rows: [0 1 2 3]\n",
      "Cols: [1 2 3 0]\n",
      "Data: [1. 1. 1. 1.]\n",
      "\n",
      "Dense representation:\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]]\n",
      "\n",
      "Symmetrized adjacency matrix (COO format):\n",
      "Rows: [0 0 1 1 2 2 3 3]\n",
      "Cols: [1 3 0 2 1 3 0 2]\n",
      "Data: [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Dense representation:\n",
      "[[0. 1. 0. 1.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def symmetrize_adj(mat):\n",
    "    \"\"\"\n",
    "    Given a square COO sparse matrix 'mat', return a new matrix that is symmetric.\n",
    "    For every edge (i, j) in 'mat', this adds an edge (j, i).\n",
    "    \"\"\"\n",
    "    if mat.shape[0] != mat.shape[1]:\n",
    "        raise ValueError(\"Input matrix must be square to symmetrize.\")\n",
    "\n",
    "    # Concatenate the original row and col with their counterparts swapped\n",
    "    new_row = np.concatenate([mat.row, mat.col])\n",
    "    new_col = np.concatenate([mat.col, mat.row])\n",
    "    \n",
    "    # If the original matrix has data, duplicate it. Otherwise, use 1's for edges.\n",
    "    if mat.data is not None and len(mat.data) > 0:\n",
    "        new_data = np.concatenate([mat.data, mat.data])\n",
    "    else:\n",
    "        new_data = np.ones(new_row.shape[0])\n",
    "    \n",
    "    # Create the symmetric COO matrix\n",
    "    sym_mat = coo_matrix((new_data, (new_row, new_col)), shape=mat.shape)\n",
    "    \n",
    "    # Remove duplicate entries by summing them up (if any)\n",
    "    sym_mat.sum_duplicates()\n",
    "    return sym_mat\n",
    "\n",
    "def main():\n",
    "    # Create a directed adjacency matrix example:\n",
    "    # Let's define a 4x4 matrix with edges:\n",
    "    # 0 -> 1, 1 -> 2, 2 -> 3, 3 -> 0\n",
    "    row = np.array([0, 1, 2, 3])\n",
    "    col = np.array([1, 2, 3, 0])\n",
    "    data = np.ones(len(row))\n",
    "    adj = coo_matrix((data, (row, col)), shape=(4, 4))\n",
    "    \n",
    "    print(\"Original directed adjacency matrix (COO format):\")\n",
    "    print(\"Rows:\", adj.row)\n",
    "    print(\"Cols:\", adj.col)\n",
    "    print(\"Data:\", adj.data)\n",
    "    print(\"\\nDense representation:\")\n",
    "    print(adj.toarray())\n",
    "\n",
    "    # Apply symmetrization\n",
    "    sym_adj = symmetrize_adj(adj)\n",
    "    \n",
    "    print(\"\\nSymmetrized adjacency matrix (COO format):\")\n",
    "    print(\"Rows:\", sym_adj.row)\n",
    "    print(\"Cols:\", sym_adj.col)\n",
    "    print(\"Data:\", sym_adj.data)\n",
    "    print(\"\\nDense representation:\")\n",
    "    print(sym_adj.toarray())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
